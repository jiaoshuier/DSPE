# DSPE
 Dual Self-Paced Ensemble for Imbalanced Data Classification

本研究提出了一种双重自步集成（DSPE）框架，它将自步学习和集成学习结合在一起。 DSPE 首先计算样本难度，它衡量了正确分类的困难程度。 我们提出了一种混合样本难度，它同时考虑了样本分布和分类器的预测。 然后，根据样本难度的概率密度函数，DSPE 分别对少数类和多数类进行自步超采样（SPO）和自步欠采样（SPU），以获得平衡子集。 SPO 优先处理困难的少数类样本，而 SPU 则优先处理简单的多数类样本。 因此，安全的多数类别示例的密度高于边缘的多数类示例，而少数类别在边缘区域的密度往往高于安全区域。 通过改善密度分布，类别边界变得更加清晰。 最后，DSPE 利用多数投票法整合了在平衡子集上训练的基础分类器。 大量实验证明，DSPE 优于九种基于 SMOTE 的重采样和六种基于重采样的集成方法。
